{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 4820\n",
    "# Assignment 3: Understanding how a _feed-forward_ ANN works\n",
    "\n",
    "# Due: 2:00pm Sept 25, 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On slide 28 of _ANN Intuition Part I_ slides, there is __an ANN of 1 input layer that takes 4 inputs, followed by 2 hidden layers with 3 neurons on each hidden layer, and finally 1 output layer with 4 neurons__.\n",
    "\n",
    "Feel free to choose values for the weights and thetas. Apparently, don't choose all zeros though.\n",
    "\n",
    "Feel free to choose activation functions on the hidden layers (e.g. sigmoid, relu, tanh...). However, make sure to use  __softmax__ on the output layer.\n",
    "\n",
    "Then, like what we did in Lab 4, in Section 0 below, manually calulate the outputs from all the neurons layer by layer. Then verify your calculatations using a TensorFlow/Teras model that you build in Section 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Manually calculate the outputs from all neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "import numpy as np\n",
    "from tensorflow.keras.activations import tanh\n",
    "from tensorflow.keras.activations import sigmoid\n",
    "from tensorflow.keras.activations import softmax\n",
    "import tensorflow as tf\n",
    "\n",
    "inputs = np.array([[.5, 1, -.7, -.8]])\n",
    "\n",
    "w1 = np.array([[.4, .6, -.9],\n",
    "               [.2, -.1, 1],\n",
    "               [-1, -.5, -.2],\n",
    "               [.45, .67, .23]])\n",
    "\n",
    "t1 = np.full((3,),-.2)\n",
    "\n",
    "o1 = tanh(np.matmul(inputs, w1) + t1)\n",
    "\n",
    "w2 = np.array([[-.3, -.21, -.12],\n",
    "               [.68, .39, .12],\n",
    "               [.54, -.6, .3]])\n",
    "\n",
    "t2 = np.full((3,), 0.1)\n",
    "\n",
    "o2 = sigmoid(np.matmul(o1, w2) + t2)\n",
    "\n",
    "w3 = np.array([[.9, .7, -.82, .41],\n",
    "               [-.3, 1, .49, -.42],\n",
    "               [.12, -.2, -.81, .58]])\n",
    "\n",
    "t3 = np.full((4,), -.31)\n",
    "\n",
    "output = softmax(tf.convert_to_tensor(np.matmul(o2, w3) + t3)).numpy()\n",
    "\n",
    "# print('Input into the network: \\n', inputs, '\\n\\n')\n",
    "# print('Weights between first hidden layer and second: \\n', w1, '\\n\\n')\n",
    "# print('Theta (bias) for first hidden layer: \\n', t1, '\\n\\n')\n",
    "# print('Output from first hidden layer: \\n', o1, '\\n\\n')\n",
    "# print('Weights between second hidden layer and output layer: \\n', w2, '\\n\\n')\n",
    "# print('Theta (bias) for second hidden layer: \\n', t2, '\\n\\n')\n",
    "# print('Output from second hidden layer: \\n', o2, '\\n\\n')\n",
    "# print('Weights on connections leaving output layer: \\n', w3, '\\n\\n')\n",
    "# print('Theta (bias) for output layer: \\n', t3, '\\n\\n')\n",
    "# print('Final output of simualted neural network: \\n', output, '\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Build a model in Keras to verify the calculations above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(3, input_shape=(4,), activation='tanh'))\n",
    "model.add(Dense(3, activation='sigmoid'))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "model.layers[0].set_weights([w1, t1])\n",
    "model.layers[1].set_weights([w2, t2])\n",
    "model.layers[2].set_weights([w3, t3])\n",
    "\n",
    "y_pred = model.predict(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.27277335 0.36825176 0.10041202 0.25856288]]\n",
      "[[0.27277336 0.36825174 0.10041201 0.2585629 ]]\n",
      "They match!\n"
     ]
    }
   ],
   "source": [
    "# Assuming \"output\" is the row matrix that has the final results of your manual calculations from Section 0 above\n",
    "print(output)\n",
    "# Assuming \"y_pred\" is the row matrix that has the final results of your ANN model from Section 1 above\n",
    "print(y_pred)\n",
    "\n",
    "if (np.isclose(y_pred, output).all()):\n",
    "    print(\"They match!\")\n",
    "else:\n",
    "    print(\"They don't match...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
